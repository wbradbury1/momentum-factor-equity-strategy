{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1791d557-bd41-43d6-981e-2729e9d6e939",
   "metadata": {},
   "source": [
    "# Backtesting Momentum Strategy  \n",
    "\n",
    "**Author:** William Bradbury  \n",
    "\n",
    "**Email:** wbradbury1@outlook.com  \n",
    "\n",
    "**LinkedIn:** https://www.linkedin.com/in/williamjbradbury/  \n",
    "\n",
    "**GitHub:** https://github.com/wbradbury1  \n",
    "\n",
    "**Affiliation:** University of Warwick — BSc Mathematics \n",
    "\n",
    "This notebook implements and evaluates a **cross-sectional momentum trading strategy** on the S&P 500 (2010–2025).  \n",
    "It compares two portfolio constructions: **long-only (Top 40)** and **long–short (Top 20 vs. Bottom 20)**, with a 12–1 lookback and monthly rebalancing.  \n",
    "The notebook is formatted for GitHub: no outputs, execution counts stripped, and code formatted.  \n",
    "\n",
    "## Features  \n",
    "- Historical S&P 500 membership (no survivorship bias)  \n",
    "- Price data via `yfinance` (adjusted close)  \n",
    "- Configurable parameters: lookback, basket size, transaction costs  \n",
    "- Portfolio constructions: long-only or long–short  \n",
    "- Metrics: CAGR, Annualized Vol, Sharpe, Max Drawdown, Hit Rate  \n",
    "- Plots: equity curves vs SPY, drawdowns, turnover  \n",
    "\n",
    "## How to Run  \n",
    "1. Install the required packages:\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "2. Open the notebook in Jupyter (`jupyter lab`).\n",
    "3. Run all cells in order. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579f72b-faf3-4d3b-b2f0-0f169549f0f4",
   "metadata": {},
   "source": [
    "## 1) Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502ebcc-66a2-41ae-8f72-3b1276cda5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If yfinance not installed and error returned, uncomment following line:\n",
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b57c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9273c45",
   "metadata": {},
   "source": [
    "## 2) Load S&P 500 historical constituents + Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180eb1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical S&P 500 constituents CSV\n",
    "# index_col=0 -> first column (dates) becomes the DataFrame index\n",
    "c_df = pd.read_csv(\"constituents_sp500.csv\", index_col=0)\n",
    "# Convert index from strings to Timestamps so we can compare/slice by date\n",
    "c_df.index = pd.to_datetime(c_df.index)\n",
    "# Keep dates in ascending order (oldest -> newest). This is important for the search logic below. (MORE IF CSV ISNT FORMATTED CORRECTLY)\n",
    "c_df = c_df.sort_index()\n",
    "c_df.head(3)  # quick check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24974d-cf68-4a43-8542-3d6322aa4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tickers_date(c_df, date):\n",
    "    #Return tickers that belong to the S&P 500 ON or AFTER 'date' (first row >= date).\n",
    "    #Why this matters: we want the **historically correct** universe for each rebalance, so the backtest is not survivorship-biased.\n",
    "    \n",
    "    d = pd.to_datetime(date)              # ensure comparable type\n",
    "    idx = c_df.index                      # DatetimeIndex of change dates\n",
    "    \n",
    "    if d >= idx[-1]:\n",
    "        # If you ask for a date beyond our CSV, return the most recent lineup\n",
    "        ticks_str = c_df.iloc[-1].tickers\n",
    "    else:\n",
    "        # First row whose index >= d\n",
    "        pos = idx.searchsorted(d, side=\"left\")\n",
    "        ticks_str = c_df.iloc[pos].tickers\n",
    "    \n",
    "    # Due to CSV is formatting; split on commas to get a Python list\n",
    "    return ticks_str.split(\",\")\n",
    "\n",
    "# Example: query a date after the file ends -> returns last known membership\n",
    "get_tickers_date(c_df, pd.Timestamp(\"2026-01-01\"))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc3b22",
   "metadata": {},
   "source": [
    "## 2) Download S&P 500 prices and compute 12-1 momentum factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6445e-a9e5-4c3a-904a-6d56fd5ac49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "#going for a neutral startegy here \n",
    "N_LONG  = 20 # number of stocks to go long (top-20 idea)\n",
    "N_SHORT = 20 # number of stocks to go short (symmetric short side, makes portfolio market-neutral)\n",
    "TC_BPS  = 10.0               # trading transaction costs, in basis points (0.01%). Applied when calculating turnover. 10 is approximation\n",
    "MIN_HISTORY_MONTHS = 24      # minimum months of historical data required before a stock is eligible (prevents using very short/noisy time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d455fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Download prices for the union of historical S&P 500 members & build 12-1 momentum ===\n",
    "START = \"2010-01-01\"\n",
    "start_dt = pd.to_datetime(START)\n",
    "\n",
    "# include buffer to ensure enough lookback for momentum and eligibility\n",
    "buffer_months = max(12, MIN_HISTORY_MONTHS)\n",
    "union_from = start_dt - pd.DateOffset(months=buffer_months)\n",
    "\n",
    "# union of all members that appear at/after union_from\n",
    "hist_members = []\n",
    "for d, row in c_df.loc[c_df.index >= union_from].iterrows():\n",
    "    hist_members += [t.strip() for t in row.tickers.split(\",\")]\n",
    "tickers_all = sorted(set(hist_members))\n",
    "print(\"Tickers in historical union:\", len(tickers_all))\n",
    "\n",
    "# download adjusted closes for full union\n",
    "df = yf.download(tickers_all, start=union_from.strftime(\"%Y-%m-%d\"),\n",
    "                 auto_adjust=True, progress=False)[\"Close\"]\n",
    "\n",
    "# month-end prices & momentum (12-1)\n",
    "monthly_prices = df.resample(\"ME\").last()\n",
    "momentum = monthly_prices.pct_change(12, fill_method=None).shift(1)\n",
    "\n",
    "# trim to actual backtest window\n",
    "monthly_prices = monthly_prices.loc[start_dt:]\n",
    "momentum       = momentum.loc[start_dt:]\n",
    "\n",
    "momentum.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e7301-1cda-43b1-b1f9-134d67f30bfd",
   "metadata": {},
   "source": [
    "## 3) Define Backtest Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18da8e-5f1f-4d24-bc6e-7c711353252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#strategy functions \n",
    "def eligible_universe(pf_scores, date, c_df, monthly_prices, min_hist=MIN_HISTORY_MONTHS): #note pf_scores is portfolio score we take from momentum dataframe for that date\n",
    "    #Filter tickers that (i) are members on 'date' and (ii) have at least min_hist months of data up to 'date'.\n",
    "    # 1) historical membership\n",
    "    members = set(get_tickers_date(c_df, date))\n",
    "    pf_scores = pf_scores[pf_scores.index.isin(members)] \n",
    "    if pf_scores.empty:\n",
    "        return pf_scores.index[:0]  # empty index\n",
    "\n",
    "    # 2) data availability\n",
    "    counts = monthly_prices.loc[:date, pf_scores.index].iloc[:-1].count()\n",
    "    have_enough = counts[counts >= min_hist].index\n",
    "    return pf_scores.index.intersection(have_enough)\n",
    "\n",
    "def pick_baskets(pf_scores, longs=N_LONG, shorts=N_SHORT):\n",
    "    #Return (Index of long tickers, Index of short tickers) from a score Series.\n",
    "    s = pf_scores.dropna().sort_values(ascending=False) #formats data, sorts by porfolio score (current asset momentum) in descending order\n",
    "    longs_idx  = s.head(longs).index # choses N_LONG best performers to long\n",
    "    shorts_idx = s.tail(shorts).index # choses N_SHORT worst perfromers to short\n",
    "    return longs_idx, shorts_idx\n",
    "\n",
    "def make_dollar_neutral_weights(all_cols, longs_idx, shorts_idx): # all_cols = list of all tickers (so every stock in the s&p universe has a slot, even if it’s not held)\n",
    "    #Equal-weight +0.5 across longs and -0.5 across shorts.\n",
    "    #Total gross exposure = 1.0 (0.5 long + 0.5 short).\n",
    "    w = pd.Series(0.0, index=all_cols, dtype=float) # creates a Series of portfolio weights, initially all 0.0.\n",
    "    if len(longs_idx) > 0:\n",
    "        w.loc[longs_idx] = +0.5 / len(longs_idx) # For each long stock, assign an equal weight. Example: if there are 20 longs, each gets +0.5 / 20 = +0.025 (2.5%). So the total long side sums to +0.5\n",
    "    if len(shorts_idx) > 0:\n",
    "        w.loc[shorts_idx] = -0.5 / len(shorts_idx) # Same for shorts, but negative.\n",
    "    return w # list where index tickers, value portfolio weight\n",
    "\n",
    "def turnover(prev_w, w): # how much of your portfolio you traded when you rebalanced, expressed as a fraction of portfolio value.\n",
    "    return 0.5 * (w.fillna(0.0) - prev_w.fillna(0.0)).abs().sum() #turnover\n",
    "\n",
    "def cost_from_turnover(tovr, tc_bps=TC_BPS): #portfolio drag that month due to turnover fees\n",
    "    return (tc_bps / 1e4) * tovr #bps to decimal *  turnover\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a211e8-bfab-4b57-b715-7b2bde5ad075",
   "metadata": {},
   "source": [
    "## 4) Backtest Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cecad0-bb2f-4b5c-8a0c-59454e95521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_rets = monthly_prices.pct_change(fill_method=None).fillna(0.0)\n",
    "\n",
    "# Storage for realized returns and turnover\n",
    "portfolio   = pd.DataFrame(index=monthly_prices.index, columns=monthly_prices.columns, dtype=float) # a DataFrame to record the weights you hold each rebalance month (NaN = not holding that ticker this month).\n",
    "gross_list  = [] # list of gross portfolio returns (before costs) each month\n",
    "net_list    = [] # list of net returns (after subtracting trading costs)\n",
    "tovr_list   = [] # list of turnover values each month\n",
    "realized_dates = [] # dates our backtest is active\n",
    "\n",
    "# Keep previous weights to compute turnover; start at 0% everywhere (no holding initially)\n",
    "prev_w = pd.Series(0.0, index=monthly_prices.columns, dtype=float)\n",
    "\n",
    "# iterate only over dates where we have momentum scores\n",
    "dates = momentum.index # momentum table defines the rebalance calendar (end-of-month dates)\n",
    "for i in range(12, len(dates) - 1): # Start at 12 so a 12-month momentum signal exists. Stop at len(dates) - 1 because you’ll realize next month’s return (i+1) for the PnL\n",
    "    date = dates[i] # Current rebalance date\n",
    "    next_date = dates[i + 1]\n",
    "    pf_scores = momentum.loc[date].copy() # Cross-section of scores (momentum) for this date; a Series indexed by ticker.\n",
    "\n",
    "    # eligibility\n",
    "    elig = eligible_universe(pf_scores, date, c_df, monthly_prices, MIN_HISTORY_MONTHS)\n",
    "    if len(elig) == 0:\n",
    "        realized_dates.append(next_date)       \n",
    "        # hold cash\n",
    "        portfolio.loc[date] = np.nan\n",
    "        gross_list.append(0.0); net_list.append(0.0); tovr_list.append(0.0)\n",
    "        prev_w = pd.Series(0.0, index=monthly_prices.columns, dtype=float)\n",
    "        continue # skip rest of loop for efficiency\n",
    "\n",
    "    # baskets & weights\n",
    "    longs_idx, shorts_idx = pick_baskets(pf_scores.loc[elig], N_LONG, N_SHORT)\n",
    "    w = make_dollar_neutral_weights(monthly_prices.columns, longs_idx, shorts_idx)\n",
    "    portfolio.loc[date] = w #Store the weights you actually hold for this date\n",
    "\n",
    "    # realize next month's return\n",
    "    \n",
    "    r_next = monthly_rets.loc[next_date]  # returns for all tickers in the next month \n",
    "    gross = float((w * r_next).sum()) # weight-weighted sum of next month’s returns\n",
    "    tovr  = turnover(prev_w, w) # how much you changed the portfolio vs last month\n",
    "    cost  = cost_from_turnover(tovr, TC_BPS)\n",
    "    net   = gross - cost\n",
    "\n",
    "    gross_list.append(gross)\n",
    "    net_list.append(net)\n",
    "    tovr_list.append(tovr)\n",
    "    realized_dates.append(next_date)       \n",
    "\n",
    "    prev_w = w  # Carry today’s weights forward to compare against at the next rebalance\n",
    "\n",
    "# Build the returns series aligned to the realized months (we realized from t -> t+1)\n",
    "ret_index       = pd.Index(realized_dates, name=\"Date\")\n",
    "strategy_gross  = pd.Series(gross_list, index=ret_index, name=\"Gross\")\n",
    "strategy_net    = pd.Series(net_list,   index=ret_index, name=\"Net\")\n",
    "turnover_series = pd.Series(tovr_list,  index=ret_index, name=\"Turnover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a3fec",
   "metadata": {},
   "source": [
    "## 5) Benchmark against SPY with plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b07015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Benchmark data import (SPY ETF instead of ^GSPC) ===\n",
    "# SPY launched in 1993, so safe to use from 2000 onwards\n",
    "\n",
    "bench = yf.download(\"SPY\", start=START, auto_adjust=True, progress=False)[\"Close\"]  \n",
    "bench_m = bench.resample(\"ME\").last()          # month-end closes\n",
    "bench_ret = bench_m.pct_change(fill_method=None)  # monthly returns (dividends already in adj close)\n",
    "\n",
    "# Align benchmark to strategy dates (so shapes match)\n",
    "bench_aligned = bench_ret.reindex(strategy_net.index)\n",
    "bench_aligned = bench_aligned.fillna(0.0).squeeze()\n",
    "bench_aligned.name = \"SPY\"\n",
    "\n",
    "# 1) Build equity curves\n",
    "eq_strategy = (1 + strategy_net).cumprod().rename(\"Strategy (Net)\")\n",
    "eq_bench    = (1 + bench_aligned).cumprod().rename(bench_aligned.name)\n",
    "\n",
    "# 2) Plot equity curves (same axes)\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "eq_strategy.plot(ax=ax, label=eq_strategy.name)\n",
    "eq_bench.plot(ax=ax, label=eq_bench.name)\n",
    "ax.set_title(\"Equity Curves — Strategy vs SPY (Net of Costs)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Cumulative Growth of $1\")\n",
    "ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) Compute drawdowns for both\n",
    "dd_strategy = eq_strategy / eq_strategy.cummax() - 1.0\n",
    "dd_bench    = eq_bench / eq_bench.cummax() - 1.0\n",
    "\n",
    "# 4) Plot drawdowns (same axes)\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "dd_strategy.plot(ax=ax, label=\"Strategy Drawdown\")\n",
    "dd_bench.plot(ax=ax, label=f\"{eq_bench.name} Drawdown\", alpha=0.8)\n",
    "ax.set_title(\"Drawdowns — Strategy vs SPY\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Drawdown\")\n",
    "ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1310fe5",
   "metadata": {},
   "source": [
    "## 6) Compare Performance metrics (CAGR, Vol, Sharpe, MaxDD, HitRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afc3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_return(x, n=12):\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        x = x.iloc[:, 0]\n",
    "    if len(x) == 0:\n",
    "        return 0.0\n",
    "    return float((1 + x).prod() ** (n / len(x)) - 1.0)\n",
    "\n",
    "def ann_vol(x, n=12):\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        x = x.iloc[:, 0]\n",
    "    return float(x.std(ddof=0) * np.sqrt(n))\n",
    "\n",
    "def sharpe(x, n=12):\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        x = x.iloc[:, 0]\n",
    "    s = float(x.std(ddof=0))\n",
    "    if s == 0.0:\n",
    "        return 0.0\n",
    "    return float(x.mean()) / s * np.sqrt(n)\n",
    "\n",
    "def maxdd(x):\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        x = x.iloc[:, 0]\n",
    "    eq = (1 + x).cumprod()\n",
    "    return float((eq / eq.cummax() - 1.0).min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04326663-92c5-4efd-a9f1-505b52d11e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_net = strategy_net.squeeze()\n",
    "bench_aligned = bench_aligned.squeeze()\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"CAGR\":   [ann_return(strategy_net), ann_return(bench_aligned)],\n",
    "    \"Vol_A\":  [ann_vol(strategy_net),    ann_vol(bench_aligned)],\n",
    "    \"Sharpe\": [sharpe(strategy_net),     sharpe(bench_aligned)],\n",
    "    \"MaxDD\":  [maxdd(strategy_net),      maxdd(bench_aligned)],\n",
    "    \"HitRate\":[float((strategy_net > 0).mean()),\n",
    "               float((bench_aligned > 0).mean())]\n",
    "}, index=[\"Strategy (Net)\", \"SPY\"])\n",
    "\n",
    "# print as table\n",
    "display(summary.assign(\n",
    "    CAGR   = summary[\"CAGR\"].map(lambda x: f\"{x:.2%}\"),\n",
    "    Vol_A  = summary[\"Vol_A\"].map(lambda x: f\"{x:.2%}\"),\n",
    "    MaxDD  = summary[\"MaxDD\"].map(lambda x: f\"{x:.2%}\"),\n",
    "    HitRate= summary[\"HitRate\"].map(lambda x: f\"{x:.2%}\"),\n",
    "    Sharpe = summary[\"Sharpe\"].map(lambda x: f\"{x:.2f}\")\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b809aff2-3060-4aa8-940f-6e75fab90db7",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "\n",
    "The momentum strategy was evaluated on the S&P 500 universe from 2010–2025 using a 12–1 lookback and monthly rebalancing. Two variants were tested: (A) long-only top 40 stocks, and (B) long–short top 20 vs. bottom 20 stocks.  \n",
    "\n",
    "- **CAGR:** Long-only generated 8.08% annually vs. SPY’s 13.72%; the long–short portfolio lagged badly with only 0.03%.  \n",
    "- **Volatility:** All strategies had similar volatility (≈12–14%), showing no material diversification benefit.  \n",
    "- **Sharpe ratio:** Long-only achieved a moderate Sharpe of 0.63, but the long–short variant collapsed to 0.07, far below SPY’s 0.98.  \n",
    "- **Max Drawdown:** Long-only suffered –32.8% vs. SPY’s –23.9%; the long–short approach was even worse at –37.9%.  \n",
    "- **Hit Rate:** SPY was positive in ~69% of months; long-only managed ~48%, and long–short ~51%.  \n",
    "\n",
    "### Summary  \n",
    "The evidence suggests that **momentum in large-cap US equities has little value on the short side**. The long–short construction not only failed to outperform but also increased drawdowns and produced near-zero returns. The **long-only variant tracked SPY more closely**, showing some positive signal, but it still lagged the index substantially in absolute terms.  \n",
    "\n",
    "Overall, this backtest indicates that a **baseline cross-sectional momentum strategy** is not competitive with buy-and-hold SPY in this period. While the long-only side provides some signal, it is not strong enough to deliver consistent outperformance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c22ed48-0ca4-4ee7-9726-0550eb971352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
